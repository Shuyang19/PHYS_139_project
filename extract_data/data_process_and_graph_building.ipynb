{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "filename = \"/higgs/train/ntuple_merged_44.h5\"\n",
    "\n",
    "h5 = h5py.File(filename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = ['track_ptrel',     \n",
    "          'track_erel',     \n",
    "          'track_phirel',     \n",
    "          'track_etarel',     \n",
    "          'track_deltaR',\n",
    "          'track_drminsv',     \n",
    "          'track_drsubjet1',     \n",
    "          'track_drsubjet2',\n",
    "          'track_dz',     \n",
    "          'track_dzsig',     \n",
    "          'track_dxy',     \n",
    "          'track_dxysig',     \n",
    "          'track_normchi2',     \n",
    "          'track_quality',     \n",
    "          'track_dptdpt',     \n",
    "          'track_detadeta',     \n",
    "          'track_dphidphi',     \n",
    "          'track_dxydxy',     \n",
    "          'track_dzdz',     \n",
    "          'track_dxydz',     \n",
    "          'track_dphidxy',     \n",
    "          'track_dlambdadz',     \n",
    "          'trackBTag_EtaRel',     \n",
    "          'trackBTag_PtRatio',     \n",
    "          'trackBTag_PParRatio',     \n",
    "          'trackBTag_Sip2dVal',     \n",
    "          'trackBTag_Sip2dSig',     \n",
    "          'trackBTag_Sip3dVal',     \n",
    "          'trackBTag_Sip3dSig',     \n",
    "          'trackBTag_JetDistVal'\n",
    "         ]\n",
    "\n",
    "\n",
    "labels_qcd = {\"label_QCD_b\": 53, \"label_QCD_bb\":51, \"label_QCD_c\":54,\"label_QCD_cc\":52,\"label_QCD_others\": 55}\n",
    "label_H_bb = 41\n",
    "num_jets = h5[\"event_no\"].shape[0]\n",
    "n_particles = h5[\"track_dxydxy\"].shape[-1]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "edge_indices = []\n",
    "for jet in range(num_jets):\n",
    "    if h5[\"fj_label\"][jet] in list(labels_qcd.values()):\n",
    "        y.append([0,1])\n",
    "    elif h5[\"fj_label\"][jet] == label_H_bb:\n",
    "        y.append([1,0])\n",
    "    else: continue\n",
    "    \n",
    "    x = []\n",
    "    for feature in params_2:\n",
    "        x.append(h5[feature][jet])\n",
    "    X.append(np.array(x).reshape(n_particles,-1))\n",
    "    \n",
    "    # complete graph has n_particles*(n_particles-1)/2 edges, here we double count each edge, so has  n_particles*(n_particles-1) total edges\n",
    "    pairs = np.stack([[m, n] for (m, n) in itertools.product(range(n_particles), range(n_particles)) if m != n])\n",
    "    # edge_index = torch.tensor(pairs, dtype=torch.long)\n",
    "    edge_index = pairs.transpose()\n",
    "    edge_indices.append(edge_index)\n",
    "    \n",
    "    if jet > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch dataset\n",
    "datas = []\n",
    "i = 0\n",
    "data = Data(x=torch.tensor(X[i]), edge_index=torch.tensor(edge_indices[i]), y=torch.tensor(y[i], dtype=torch.long).unsqueeze(dim=0))\n",
    "for i in range(len(X)):\n",
    "    data = Data(x=torch.tensor(X[i]), edge_index=torch.tensor(edge_indices[i]), y=torch.tensor(y[i], dtype=torch.long).unsqueeze(dim=0))\n",
    "    datas.append([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])],\n",
       " [Data(x=[60, 30], edge_index=[2, 3540], y=[1, 2])]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import EdgeConv, global_mean_pool\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, BatchNorm1d\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = 30\n",
    "hidden = 128\n",
    "outputs = 2\n",
    "\n",
    "\n",
    "class EdgeBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeBlock, self).__init__()\n",
    "        self.edge_mlp = Seq(Lin(inputs * 2, hidden), BatchNorm1d(hidden), ReLU(), Lin(hidden, hidden))\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        out = torch.cat([src, dest], 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "\n",
    "class NodeBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NodeBlock, self).__init__()\n",
    "        self.node_mlp_1 = Seq(Lin(inputs + hidden, hidden), BatchNorm1d(hidden), ReLU(), Lin(hidden, hidden))\n",
    "        self.node_mlp_2 = Seq(Lin(inputs + hidden, hidden), BatchNorm1d(hidden), ReLU(), Lin(hidden, hidden))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        row, col = edge_index\n",
    "        out = torch.cat([x[row], edge_attr], dim=1)\n",
    "        out = self.node_mlp_1(out)\n",
    "        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "        out = torch.cat([x, out], dim=1)\n",
    "        return self.node_mlp_2(out)\n",
    "\n",
    "\n",
    "class GlobalBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalBlock, self).__init__()\n",
    "        self.global_mlp = Seq(Lin(hidden, hidden), BatchNorm1d(hidden), ReLU(), Lin(hidden, outputs))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        out = scatter_mean(x, batch, dim=0)\n",
    "        return self.global_mlp(out)\n",
    "\n",
    "\n",
    "class InteractionNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InteractionNetwork, self).__init__()\n",
    "        self.interactionnetwork = MetaLayer(EdgeBlock(), NodeBlock(), GlobalBlock())\n",
    "        self.bn = BatchNorm1d(inputs)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "\n",
    "        x = self.bn(x)\n",
    "        x, edge_attr, u = self.interactionnetwork(x, edge_index, None, None, batch)\n",
    "        return u\n",
    "\n",
    "\n",
    "model = InteractionNetwork().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionNetwork(\n",
       "  (interactionnetwork): MetaLayer(\n",
       "    edge_model=EdgeBlock(\n",
       "    (edge_mlp): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  ),\n",
       "    node_model=NodeBlock(\n",
       "    (node_mlp_1): Sequential(\n",
       "      (0): Linear(in_features=158, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (node_mlp_2): Sequential(\n",
       "      (0): Linear(in_features=158, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  ),\n",
       "    global_model=GlobalBlock(\n",
       "    (global_mlp): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  )\n",
       "  (bn): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, loader, total, batch_size, leave=False):\n",
    "    model.eval()\n",
    "\n",
    "    xentropy = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    t = tqdm(enumerate(loader), total=total / batch_size, leave=leave)\n",
    "    for i, data in t:\n",
    "        data = data.to(device)\n",
    "        y = torch.argmax(data.y, dim=1)\n",
    "        batch_output = model(data.x, data.edge_index, data.batch)\n",
    "        batch_loss_item = xentropy(batch_output, y).item()\n",
    "        sum_loss += batch_loss_item\n",
    "        t.set_description(\"loss = %.5f\" % (batch_loss_item))\n",
    "        t.refresh()  # to show immediately the update\n",
    "\n",
    "    return sum_loss / (i + 1)\n",
    "\n",
    "\n",
    "def train(model, optimizer, loader, total, batch_size, leave=False):\n",
    "    model.train()\n",
    "\n",
    "    xentropy = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    t = tqdm(enumerate(loader), total=total / batch_size, leave=leave)\n",
    "    for i, data in t:\n",
    "        data = data.to(device)\n",
    "        y = torch.argmax(data.y, dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(data.x, data.edge_index, data.batch)\n",
    "        batch_loss = xentropy(batch_output, y)\n",
    "        batch_loss.backward()\n",
    "        batch_loss_item = batch_loss.item()\n",
    "        t.set_description(\"loss = %.5f\" % batch_loss_item)\n",
    "        t.refresh()  # to show immediately the update\n",
    "        sum_loss += batch_loss_item\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum_loss / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[720, 30], edge_index=[2, 42480], y=[12, 2], batch=[720], ptr=[13])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data, DataListLoader, Batch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "def collate(items):\n",
    "    l = sum(items, [])\n",
    "    return Batch.from_data_list(l)\n",
    "\n",
    "\n",
    "train_dataset = datas\n",
    "valid_dataset = datas\n",
    "test_dataset = datas\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "valid_frac = 0.20\n",
    "# full_length = len(graph_dataset)\n",
    "# valid_num = int(valid_frac * full_length)\n",
    "batch_size = 32\n",
    "\n",
    "# train_dataset, valid_dataset = random_split(graph_dataset, [full_length - valid_num, valid_num])\n",
    "\n",
    "train_loader = DataListLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "train_loader.collate_fn = collate\n",
    "valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "valid_loader.collate_fn = collate\n",
    "test_loader = DataListLoader(test_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "test_loader.collate_fn = collate\n",
    "\n",
    "\n",
    "train_samples = len(train_dataset)\n",
    "valid_samples = len(valid_dataset)\n",
    "test_samples = len(test_dataset)\n",
    "# print(full_length)\n",
    "print(train_samples)\n",
    "print(valid_samples)\n",
    "print(test_samples)\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8611a22e6ff94cffa45ade46a9154824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Training Loss:   1.0887\n",
      "Validation Loss: 0.5829\n",
      "New best model saved to: interactionnetwork_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Training Loss:   0.4741\n",
      "Validation Loss: 0.5122\n",
      "New best model saved to: interactionnetwork_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Training Loss:   0.1874\n",
      "Validation Loss: 0.4260\n",
      "New best model saved to: interactionnetwork_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Training Loss:   0.0842\n",
      "Validation Loss: 0.3694\n",
      "New best model saved to: interactionnetwork_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Training Loss:   0.0622\n",
      "Validation Loss: 0.3575\n",
      "New best model saved to: interactionnetwork_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Training Loss:   0.0451\n",
      "Validation Loss: 0.3793\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Training Loss:   0.0374\n",
      "Validation Loss: 0.4248\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Training Loss:   0.0290\n",
      "Validation Loss: 0.4850\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Training Loss:   0.0223\n",
      "Validation Loss: 0.5585\n",
      "Stale epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b1edaaf9145d9a26e16727dd744b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358621359b2e4c0fbde2ffe98d0a9671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/0.375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Training Loss:   0.0155\n",
      "Validation Loss: 0.6103\n",
      "Stale epoch\n",
      "Early stopping after 5 stale epochs\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "n_epochs = 10\n",
    "stale_epochs = 0\n",
    "best_valid_loss = 99999\n",
    "patience = 5\n",
    "t = tqdm(range(0, n_epochs))\n",
    "\n",
    "for epoch in t:\n",
    "    loss = train(model, optimizer, train_loader, train_samples, batch_size, leave=bool(epoch == n_epochs - 1))\n",
    "    valid_loss = test(model, valid_loader, valid_samples, batch_size, leave=bool(epoch == n_epochs - 1))\n",
    "    print(\"Epoch: {:02d}, Training Loss:   {:.4f}\".format(epoch, loss))\n",
    "    print(\"Validation Loss: {:.4f}\".format(valid_loss))\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        modpath = osp.join(\"interactionnetwork_best.pth\")\n",
    "        print(\"New best model saved to:\", modpath)\n",
    "        torch.save(model.state_dict(), modpath)\n",
    "        stale_epochs = 0\n",
    "    else:\n",
    "        print(\"Stale epoch\")\n",
    "        stale_epochs += 1\n",
    "    if stale_epochs >= patience:\n",
    "        print(\"Early stopping after %i stale epochs\" % patience)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
